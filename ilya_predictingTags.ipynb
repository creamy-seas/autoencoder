{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "from keras.preprocessing.text import one_hot # encodes a sequence into list of integers (for embedding)\n",
    "from keras.preprocessing.text import hashing_trick # same as one hot, but do not need vocabulary\n",
    "from keras.preprocessing.sequence import pad_sequences  # pads lists to same size\n",
    "from keras.layers import Dense, Flatten, Reshape        # different neural network layers \n",
    "from keras import regularizers, Model, Input            # additiontal nn variables\n",
    "from keras.models import load_model\n",
    "\n",
    "import pickle            # writting and reading efficiently from files\n",
    "from sklearn.preprocessing import LabelBinarizer     # convert strings to output labels\n",
    "from sklearn.model_selection import train_test_split # split into training and testing data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # for 3d plotting\n",
    "plt.style.use('ilya_jupyter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# limit symbols to common a-z and other word symbols such as !#\n",
    "min_symbol = 32                 # !\n",
    "max_symbol = 122                # z\n",
    "vocabulary_size = int(max_symbol - min_symbol + 2)\n",
    "max_tag_length = 15\n",
    "\n",
    "# path definitions\n",
    "data_folder = \"./ilya_data\"\n",
    "model_tagPredictor_save = \"./ilya_model/model_tagPredictor\"\n",
    "global_param = \"./ilya_model/global_param\"\n",
    "model_autoencoder_save = \"./ilya_model/model_autoencoder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def word_to_nums(w):\n",
    "    \"\"\"convert words to number format\"\"\"\n",
    "    return [ord(c) for c in w]\n",
    "\n",
    "def convert_string_to_numeric(string_to_convert, max_tag_length=15):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    [str] string_to_convert: string to represent as an integer list\n",
    "\n",
    "    __ Description __\n",
    "    converts a string to it's numeric list representation. handles a-z and !#$...etc\n",
    "    it is padded to have a length of \"max_tag_length\" trimming any exess or padding empty spaces with 0\n",
    "\n",
    "    __ Return __\n",
    "    [int-list] numeric_representation: of string\n",
    "    \"\"\"\n",
    "\n",
    "    # 1 - cast char to integer\n",
    "    numeric_representation = np.array([ord(char) for char in string_to_convert])\n",
    "\n",
    "    # 2 - to being enumerating from zero, remove the offest for the first allowed character\n",
    "    offset = 32\n",
    "    numeric_representation = numeric_representation - offset\n",
    "\n",
    "    # 2 - pad to \"max_tag_length\" - empty spaces are filled with 0's - excess characters are trimmed\n",
    "    numeric_representation = pad_sequences([numeric_representation], max_tag_length, truncating='post', padding='post')[0]\n",
    "    \n",
    "    return numeric_representation\n",
    "\n",
    "def predict(tag, model, vocabulary_size, max_tag_length, output_labels):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    [str] word: word to predict\n",
    "    [keras] model: model to use to predict word\n",
    "    [int] vocabulary_size: vocabularly size used to encode the tags during training\n",
    "\n",
    "    __ Description __\n",
    "    returns prediction array for the given tag\n",
    "\n",
    "    __ Return __\n",
    "    [int] output_numeric, [str] output_string, [arr] probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1 - encode the tag as an integer\n",
    "    tag_integer = convert_string_to_numeric(tag)\n",
    "        \n",
    "    # 3 - run prediction\n",
    "    raw_prediction = model.predict(tag_integer)\n",
    "    \n",
    "    # 4 - create array of the form [0, 1, 0 ,0] to indicate highest value\n",
    "    output_numeric = np.argmax(raw_prediction[0])\n",
    "    output_string = output_labels[output_numeric]\n",
    "    \n",
    "    return output_numeric, output_string, raw_prediction[0]\n",
    "\n",
    "def save_parameters(lb, vocabulary_size, max_input_length,\n",
    "                    parameter_file=\"./ilya_model/global_param\"):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    [LabelBinarizer] lb: sklearn.preprocessing.LabelBinarizer that was used to create unique binaries from list of strings (output)\n",
    "    [int] vocabulary_size: vocabularly size used to encode input during training (input)\n",
    "    [int] max_input_length: length of the input (input)\n",
    "    [str] parameter_file: location to save data\n",
    "\n",
    "    __ Description __\n",
    "    stores all the parameters used by the model\n",
    "    \"\"\"\n",
    "\n",
    "    # 1 - extract all the binary labels\n",
    "    output_map = lb.classes_\n",
    "\n",
    "    # 2 - dump to file\n",
    "    with open(\"./ilya_model/global_param\", \"wb\") as fout:\n",
    "        pickle.dump({\"Output_Map\": output_map,\n",
    "                     \"Vocabulary_Size\": vocabulary_size,\n",
    "                     \"Max_Input_Length\": max_input_length},\n",
    "                    fout)\n",
    "\n",
    "def load_parameters(parameter_file=\"./ilya_model/global_param\"):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    [str] parameter_file: file to load from\n",
    "    \n",
    "    __ Description __\n",
    "    loads parameters to work with model\n",
    "\n",
    "    __ Return __\n",
    "    [list-str] output: ordered list of string output [\"description\", \"label\"]\n",
    "    \"\"\"\n",
    "    with open(\"./ilya_model/global_param\", \"rb\") as fin:\n",
    "        data = pickle.load(fin)\n",
    "\n",
    "    vocabulary_size = data[\"Vocabulary_Size\"]\n",
    "    max_input_length = data[\"Max_Input_Length\"]\n",
    "    output_labels = data[\"Output_Map\"]\n",
    "    \n",
    "    return vocabulary_size, max_input_length, output_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ Formatting the data ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘ ✘\n",
    "# - SKIP TO \"Load prepared data ← avoids running code\" if datasets are ready\n",
    "\n",
    "%time\n",
    "data_file = \"CPU.csv\"\n",
    "tags = []                       # some kind of information about device\n",
    "tags_numeric = []               # tag represetnation in number form\n",
    "field = []                   # \"Description\", \"Brand\" or \"Part Number\"\n",
    "\n",
    "# 1 - open data file, which has the columns [tag, field, irlv, irlv, irlv]\n",
    "with open(\"%s/%s\" %(data_folder, data_file), 'rnd') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, row in enumerate(reader):\n",
    "        \n",
    "        # a - get number of columns based on the number in first row\n",
    "        if (i==0):\n",
    "            n_columns = len(row)\n",
    "\n",
    "        # b - read in colums\n",
    "        temp_tags = row[0]\n",
    "        temp_tag_numeric = np.array(word_to_nums(temp_tags))\n",
    "        temp_field = row[1]\n",
    "        temp_field_numeric = np.array(word_to_nums(temp_field))\n",
    "\n",
    "        # c - skip over bad data\n",
    "        if any(temp_tag_numeric < min_symbol) or any(temp_tag_numeric > max_symbol):\n",
    "            continue\n",
    "        if (any(np.array(word_to_nums(temp_field)) > max_symbol)\n",
    "            or any( temp_field_numeric > max_symbol)):\n",
    "            continue\n",
    "        if n_columns != len(row):\n",
    "            continue\n",
    "\n",
    "        # d - store data\n",
    "        tags.append(temp_tags)\n",
    "        field.append(temp_field)\n",
    "        tags_numeric.append(temp_tag_numeric)\n",
    "        \n",
    "# 2 - import some noise data\n",
    "irr = np.load(os.path.join(data_folder, \"irrelevant_text_training.npy\"))\n",
    "\n",
    "for w in irr:\n",
    "    # a - convert to numeric format\n",
    "    temp_tag_numeric = np.array(word_to_nums(w))\n",
    "\n",
    "    # b - skip empty word and bad formatting\n",
    "    if w=='':\n",
    "        continue\n",
    "    if any(temp_tag_numeric<min_symbol) or any(temp_tag_numeric>max_symbol):\n",
    "        continue\n",
    "\n",
    "    # c - add noise to fields\n",
    "    tags.append(w)\n",
    "    field.append('Irrelevant')\n",
    "    tags_numeric.append(temp_tag_numeric)\n",
    "\n",
    "# 3 - write all data to file for easy access\n",
    "all_fields = list(set(field))   # {'Brand', 'Description', 'Part_number'}\n",
    "data = {\n",
    "    \"tags\": tags,               # all extracted tags\n",
    "    \"field\": field,             # fields that the tags are under\n",
    "    \"tags_numeric\": tags_numeric, # numeric representation\n",
    "    \"all_fields\": all_fields # {'Brand', 'Description', 'Part_number'}\n",
    "}\n",
    "with open('ilya_dataML', 'wb') as fout:\n",
    "    pickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Load prepared data ← avoids running code above\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# 1 - load in data avoiding running the above code\n",
    "with open('./ilya_model/data_verbose', 'rb') as fin:\n",
    "    data = pickle.load(fin)\n",
    "\n",
    "# 2 - extract tags and fields\n",
    "tags = data[\"tags\"]\n",
    "fields = data[\"field\"]\n",
    "all_fields = data[\"all_fields\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Preparing numeric representation of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "# 1 - encode each tag as a list of integers of length \"max_tag_length\"\n",
    "data_in = [convert_string_to_numeric(tag, max_tag_length) for tag in tags]\n",
    "\n",
    "# 2 - build output array. taking a 1D array of string\n",
    "# (e.g.['Brand', 'Part_number', 'Description', ..., 'Irrelevant')\n",
    "# and converting it to a 0s and 1s matrix i.e. [[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "data_out = np.array(fields)\n",
    "lb = LabelBinarizer()\n",
    "data_out = lb.fit_transform(data_out)\n",
    "\n",
    "# 3 - save parameters\n",
    "save_parameters(lb, vocabulary_size, max_tag_length)\n",
    "np.save(\"./ilya_model/data_in.npy\", data_in)\n",
    "np.save(\"./ilya_model/data_out.npy\", data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-708cc87a4c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1 - declare size of input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdim_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# each input tag will be a list of 15 numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdim_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# each output will be an array of 4 values [0, 0, 0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%time\n",
    "########################################\n",
    "embedding_dim = 80            # dimension of the vector that each input is cast into\n",
    "########################################\n",
    "# 1 - declare size of input\n",
    "dim_in = data_in.shape[1]    # each input tag will be a list of 15 numbers\n",
    "dim_out = data_out.shape[1]  # each output will be an array of 4 values [0, 0, 0, 1]\n",
    "\n",
    "# 2 - INPUT -> convert input sequences to embedded vectors → flatten 2D array [[s1w1, s1w2, ...], [s2w1, s2w2, ...], ...] → Normalize\n",
    "inputs = ks.Input((dim_in,))\n",
    "x = ks.layers.Embedding(vocabulary_size, embedding_dim, input_length=dim_in, name='embedding')(inputs)\n",
    "x = ks.layers.Flatten()(x)\n",
    "x = ks.layers.BatchNormalization()(x)\n",
    "\n",
    "# 3 - 1st Hidden Layer (with l1 regularizer, penalising large weight values to avoid overfitting) → Activate\n",
    "x = ks.layers.Dense(2*dim_in, kernel_regularizer=ks.regularizers.l1(0.05), name='first_dense')(x)\n",
    "x = ks.layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "# 5 - 2nd Hidden Layer → Activate → Normalize → Go to output\n",
    "x = ks.layers.Dense(2*dim_in, kernel_regularizer=ks.regularizers.l1(0.05), name='second_dense')(x)\n",
    "x = ks.layers.LeakyReLU(0.1)(x)\n",
    "x = ks.layers.BatchNormalization()(x)\n",
    "x = ks.layers.Dense(dim_out, activation='sigmoid', name='output')(x)\n",
    "\n",
    "# 6 - create model for training\n",
    "model = ks.Model(inputs=inputs, outputs=x)\n",
    "model.compile(loss=ks.losses.categorical_crossentropy, optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "model.save(model_tagPredictor_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Train NN and save logs for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 41939 samples, validate on 2208 samples\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 41.3675 - val_loss: 17.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 8.7356 - val_loss: 5.2073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 4.1263 - val_loss: 3.4666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 2.8316 - val_loss: 2.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 1.9066 - val_loss: 1.5680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 1.2278 - val_loss: 0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.8072 - val_loss: 0.7004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6098 - val_loss: 0.6016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.5438 - val_loss: 0.5391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.5144 - val_loss: 0.4955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4816 - val_loss: 0.4721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4613 - val_loss: 0.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4487 - val_loss: 0.4426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4331 - val_loss: 0.4302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4255 - val_loss: 0.4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4180 - val_loss: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4094 - val_loss: 0.4084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4038 - val_loss: 0.4054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3995 - val_loss: 0.4046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3955 - val_loss: 0.3983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3927 - val_loss: 0.4047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3893 - val_loss: 0.3863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3865 - val_loss: 0.3958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3795 - val_loss: 0.3875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.3782 - val_loss: 0.3821\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'history_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4903cc574daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 4 plot training history_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training history_log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history_log'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'history_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4903cc574daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# 4 plot training history_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training history_log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'history_log'"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "training_name = \"./ilya_model/tag_predictor_14thJune\"\n",
    "epochs = 25\n",
    "########################################\n",
    "# callbacks = [ks.callbacks.TensorBoard(embeddings_freq=10, embeddings_layer_names='embedding',\n",
    "# embeddings_data=testing_in[:100, :])]\n",
    "# 1 - Prepare training and testing datasets: Randomise the word inputs,  Select 90% for training, and 10% for testing\n",
    "(in_train, in_test, out_train, out_test) = train_test_split(data_in, data_out, test_size = 0.1, random_state=42, shuffle=True)\n",
    "\n",
    "# 2 - load the compiled model and begin training\n",
    "model = ks.models.load_model(model_tagPredictor_save)\n",
    "history_log = model.fit(in_train, out_train, verbose=2, epochs=epochs,\n",
    "          batch_size=1000,validation_split=0.05)#, callbacks=callbacks)  # starts training\n",
    "            \n",
    "# 3 - save the weights\n",
    "model.save(training_name)\n",
    "\n",
    "# 4 plot training history_log\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.plot(history_log.history_log[\"loss\"])\n",
    "ax.plot(history_log.history_log[\"val_loss\"], color=\"C4\")\n",
    "ax.set_title(\"Training history_log\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend([\"Train\", \"Valdiation\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "With managable errors:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "n_tests = 1000\n",
    "########################################\n",
    "model = ks.models.load_model(training_name)\n",
    "vocabulary_size, max_input_length, output_labels = load_parameters(global_param)\n",
    "\n",
    "n_successes = 0\n",
    "n_managable_errors = 0\n",
    "i = 0\n",
    "while i < n_tests:\n",
    "    try:\n",
    "        i += 1\n",
    "\n",
    "        # 1 - extract random value in string format\n",
    "        rnd = np.random.randint(0, len(tags))\n",
    "        tag = tags[rnd]\n",
    "        true_field = fields[rnd]\n",
    "        \n",
    "        # 2 - predict and compare\n",
    "        field_numeric, field_string, raw_prediction = predict(tag, model, vocabulary_size, max_tag_length, output_labels)\n",
    "        \n",
    "        # 3 - run prediction\n",
    "        if (field_string == true_field):\n",
    "            n_successes += 1\n",
    "        elif ({field_numeric, true_field} == {\"Description\", \"Irrelevant\"} or tag==\"AMD\"):\n",
    "            n_managable_errors += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(n_successes/n_tests*100, '%')\n",
    "print('With managable errors: ', (n_managable_errors + n_successes)/n_tests*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/200 [===>..........................] - ETA: 5s - loss: 71.7651"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 1s 5ms/step - loss: 67.7089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t37\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 60.5499"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 164us/step - loss: 56.6002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t40\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 50.1515"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 164us/step - loss: 46.6027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t49\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 40.9145"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 151us/step - loss: 37.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t62\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 32.6381"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 184us/step - loss: 30.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t66\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 25.5723"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 178us/step - loss: 23.3270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t75\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 19.9256"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 151us/step - loss: 18.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t78\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 15.2699"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 171us/step - loss: 13.7080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t76\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 11.5525"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 157us/step - loss: 10.4226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t76\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 8.8729"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 153us/step - loss: 8.3161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t70\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 7.5152"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 159us/step - loss: 7.2697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t70\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 6.8125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 152us/step - loss: 6.6502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t73\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 6.3627"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 172us/step - loss: 6.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t74\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 5.9696"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 145us/step - loss: 5.7114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t67\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 5.4872"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 179us/step - loss: 5.2921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t74\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 5.1150"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 153us/step - loss: 4.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t76\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 4.8455"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 159us/step - loss: 4.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t74\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 4.8036"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 146us/step - loss: 4.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t77\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 4.5891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 144us/step - loss: 4.4287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t85\n",
      "Epoch 1/1\n",
      "\r",
      " 32/200 [===>..........................] - ETA: 0s - loss: 4.2614"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "200/200 [==============================] - 0s 177us/step - loss: 4.2848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t80\n"
     ]
    }
   ],
   "source": [
    "# 1 - load model and parameters\n",
    "model = ks.models.load_model(model_tagPredictor_save)\n",
    "vocabulary_size, max_input_length, output_labels = load_parameters(global_param)\n",
    "\n",
    "# 2 - upload training dataset\n",
    "train_in = np.load(\"./ilya_model/data_in.npy\")\n",
    "train_out = np.load(\"./ilya_model/data_out.npy\")\n",
    "\n",
    "# 3 - train the model on batches of200 random values\n",
    "training_size = 200\n",
    "for i in range(0,20):\n",
    "    train_indx = np.random.randint(0, len(train_in), size=training_size)\n",
    "    model.fit(train_in[train_indx, :], train_out[train_indx, :],\n",
    "              verbose=1, epochs=1, batch_size=32)\n",
    "\n",
    "    # b - check quality\n",
    "    correct = 0\n",
    "    for i in range(0, 100):\n",
    "        # a - take random tag and run prediction\n",
    "        indx = np.random.randint(len(tags))\n",
    "        tag = tags[indx]\n",
    "        true_field = fields[indx]\n",
    "        \n",
    "        predict_numeric, predict_string, predict_raw = predict(\n",
    "            tag, model, vocabulary_size, max_input_length, output_labels)\n",
    "\n",
    "        if (predict_string == true_field):\n",
    "            correct += 1\n",
    "\n",
    "    print(\"\\t\\t\\t\\t\\t%s\" % (correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Playing with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = ks.models.load_model(model_tagPredictor_save)\n",
    "model.layers[-4].get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Autoencoder - make sure \"data_in\" is loaded from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Use the trained \"tag_model\" to embed the tags into a (15x80) Dense vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-636c25047924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1 - create a model that takes in tags and outputs their embedded vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#   - effecitvely this is the first layer of the \"tag_predictor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2 - run model on input tags, to turn each character into an embedded vector (?, 15) → (?, 15, 80)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 1 - create a model that takes in tags and outputs their embedded vectors\n",
    "#   - effecitvely this is the first layer of the \"tag_predictor\"\n",
    "model_embed = Model(tag_model.inputs, tag_model.get_layer(\"embedding\").output)\n",
    "\n",
    "# 2 - run model on input tags, to turn each character into an embedded vector (?, 15) → (?, 15, 80) \n",
    "tags_embeded = model_embed.predict(data_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Pass the embeded tags to the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15x80 (InputLayer)     (None, 15, 80)            0         \n",
      "_________________________________________________________________\n",
      "flattend_15x80 (Flatten)     (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "encoding (Dense)             (None, 3)                 3603      \n",
      "_________________________________________________________________\n",
      "decoding (Dense)             (None, 1200)              4800      \n",
      "_________________________________________________________________\n",
      "reshaped_15x80 (Reshape)     (None, 15, 80)            0         \n",
      "=================================================================\n",
      "Total params: 8,403\n",
      "Trainable params: 8,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "encoding_funnel_dimension = 3\n",
    "########################################\n",
    "dim_in_1 = tags_embeded.shape[1]\n",
    "dim_in_2 = tags_embeded.shape[2]\n",
    "\n",
    "# 1 - input layer (?, 15, 80) → flatten to (?, 1200)\n",
    "input_LAYER = Input((dim_in_1, dim_in_2), name=\"input_15x80\")\n",
    "flattened_LAYER = Flatten(name=\"flattend_15x80\")(input_LAYER)\n",
    "\n",
    "# 2 - middle \"funnel\" or encoding\n",
    "encoding_LAYER = Dense(encoding_funnel_dimension, activation='relu', name=\"encoding\",\n",
    "                    activity_regularizer=regularizers.l1(10e-5))(flattened_LAYER)\n",
    "\n",
    "# 3 - decode the funneled layer → reshape\n",
    "decoding_LAYER = Dense(dim_in_1 * dim_in_2, activation='sigmoid',\n",
    "                       name=\"decoding\")(encoding_LAYER)\n",
    "unflattened_LAYER = Reshape((dim_in_1, dim_in_2), name=\"reshaped_15x80\")(decoding_LAYER)\n",
    "\n",
    "# 4 - compile model\n",
    "model_autoencoder = Model(input_LAYER, unflattened_LAYER)\n",
    "model_autoencoder.compile(optimizer='adam', loss='mse')\n",
    "print(model_autoencoder.summary())\n",
    "model_autoencoder.save(model_autoencoder_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/CCCP/creamy_seas/syncFiles/python_vi/nn_vi/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tags_embeded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-51a70d0adc86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1 - load the compiled model and begin training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history_log = model.fit(tags_embeded, tags_embeded, verbose=1, epochs=epochs,\n\u001b[0m\u001b[1;32m      8\u001b[0m           batch_size=1000, validation_split=0.05)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tags_embeded' is not defined"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "training_name = \"./ilya_model/model_autoencoder_14thJune\"\n",
    "epochs = 25\n",
    "########################################\n",
    "# 1 - load the compiled model and begin training\n",
    "model = ks.models.load_model(model_autoencoder_save)\n",
    "history_log = model.fit(tags_embeded, tags_embeded, verbose=1, epochs=epochs,\n",
    "          batch_size=1000, validation_split=0.05)\n",
    "            \n",
    "# 3 - save the weights\n",
    "model.save(training_name)\n",
    "\n",
    "# 4 plot training history_log\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.plot(history_log.history[\"loss\"])\n",
    "ax.plot(history_log.history[\"val_loss\"], color=\"C4\")\n",
    "ax.set_title(\"Training history_log\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend([\"Train\", \"Valdiation\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-810f07934ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviz_input_LAYER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_15x80\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mviz_output_LAYER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvizualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz_input_LAYER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mviz_output_LAYER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2 - run vizualisation on some of the tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "viz_input_LAYER = model_autoencoder.get_layer(\"input_15x80\").input\n",
    "viz_output_LAYER = model_autoencoder.get_layer(\"encoding\").output\n",
    "vizualization_model = Model(viz_input_LAYER, viz_output_LAYER)\n",
    "\n",
    "# 2 - run vizualisation on some of the tags\n",
    "indx = np.random.randint(len(tags_embeded), size=400)\n",
    "tags_encoded = vizualization_model.predict(tags_embeded[indx])\n",
    "tag_fields = np.argmax(data_out[indx], axis=1) # extract the field that each tag belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f8507f61ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %matplotlib qt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'navy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'turquoise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'darkorange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'navy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'turquoise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'darkorange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "colours = ['navy', 'turquoise', 'darkorange', 'red']\n",
    "\n",
    "    \n",
    "for colour, i, label in zip(colours, [0, 1, 2, 3], output_labels):\n",
    "    ax.scatter(tags_encoded[tag_fields==i, 0],\n",
    "               tags_encoded[tag_fields==i, 1],\n",
    "               tags_encoded[tag_fields==i, 2],\n",
    "               color=colour,\n",
    "               label=label)\n",
    "plt.show()\n",
    "# tags_encoded.shape[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 1 - take embedding layer of the \"tag_predictor model\"\n",
    "# the TRAINDE model will have the fitted weights that groups characters by context\n",
    "tag_model = load_model(training_name)\n",
    "embedding_LAYER = tag_model.get_layer(\"embedding\")\n",
    "# 92 characters, each with an 80-dimensional vector\n",
    "embedding_LAYER.get_weights()[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "ilya_predictingTags.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
